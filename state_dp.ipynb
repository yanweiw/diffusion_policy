{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import zarr\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_indices(\n",
    "        episode_ends:np.ndarray, sequence_length:int,\n",
    "        pad_before: int=0, pad_after: int=0):\n",
    "    indices = list()\n",
    "    for i in range(len(episode_ends)):\n",
    "        start_idx = 0\n",
    "        if i > 0:\n",
    "            start_idx = episode_ends[i-1]\n",
    "        end_idx = episode_ends[i]\n",
    "        episode_length = end_idx - start_idx\n",
    "\n",
    "        min_start = -pad_before\n",
    "        max_start = episode_length - sequence_length + pad_after\n",
    "\n",
    "        # range stops one idx before end\n",
    "        for idx in range(min_start, max_start+1):\n",
    "            buffer_start_idx = max(idx, 0) + start_idx\n",
    "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
    "            start_offset = buffer_start_idx - (idx+start_idx)\n",
    "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
    "            sample_start_idx = 0 + start_offset\n",
    "            sample_end_idx = sequence_length - end_offset\n",
    "            indices.append([\n",
    "                buffer_start_idx, buffer_end_idx,\n",
    "                sample_start_idx, sample_end_idx])\n",
    "    indices = np.array(indices)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def sample_sequence(train_data, sequence_length,\n",
    "                    buffer_start_idx, buffer_end_idx,\n",
    "                    sample_start_idx, sample_end_idx):\n",
    "    result = dict()\n",
    "    for key, input_arr in train_data.items():\n",
    "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
    "        data = sample\n",
    "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
    "            data = np.zeros(\n",
    "                shape=(sequence_length,) + input_arr.shape[1:],\n",
    "                dtype=input_arr.dtype)\n",
    "            if sample_start_idx > 0:\n",
    "                data[:sample_start_idx] = sample[0]\n",
    "            if sample_end_idx < sequence_length:\n",
    "                data[sample_end_idx:] = sample[-1]\n",
    "            data[sample_start_idx:sample_end_idx] = sample\n",
    "        result[key] = data\n",
    "    return result\n",
    "\n",
    "# normalize data\n",
    "def get_data_stats(data):\n",
    "    data = data.reshape(-1,data.shape[-1])\n",
    "    stats = {\n",
    "        'min': np.min(data, axis=0),\n",
    "        'max': np.max(data, axis=0)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "def normalize_data(data, stats):\n",
    "    # nomalize to [0,1]\n",
    "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
    "    # normalize to [-1, 1]\n",
    "    ndata = ndata * 2 - 1\n",
    "    return ndata\n",
    "\n",
    "def unnormalize_data(ndata, stats):\n",
    "    ndata = (ndata + 1) / 2\n",
    "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
    "    return data\n",
    "\n",
    "# dataset\n",
    "class CuroboStateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path,\n",
    "                 pred_horizon, obs_horizon, action_horizon):\n",
    "\n",
    "        # read from zarr dataset\n",
    "        # dataset_root = zarr.open(dataset_path, 'r')\n",
    "\n",
    "        # All demonstration episodes are concatinated in the first dimension N\n",
    "        train_data = {\n",
    "            # (N, action_dim)\n",
    "            'action': dataset_root['data']['action'][:], # the pusht example gives (25650, 2)\n",
    "            # (N, obs_dim)\n",
    "            'obs': dataset_root['data']['state'][:] # the pusht example gives (25650, 5)\n",
    "        }\n",
    "        # Marks one-past the last index for each episode\n",
    "        episode_ends = dataset_root['meta']['episode_ends'][:] # the pusht dataset has shape (206,)\n",
    "\n",
    "        # compute start and end of each state-action sequence\n",
    "        # also handles padding\n",
    "        indices = create_sample_indices(\n",
    "            episode_ends=episode_ends,\n",
    "            sequence_length=pred_horizon,\n",
    "            # add padding such that each timestep in the dataset are seen\n",
    "            pad_before=obs_horizon-1,\n",
    "            pad_after=action_horizon-1)\n",
    "\n",
    "        # compute statistics and normalized data to [-1,1]\n",
    "        stats = dict()\n",
    "        normalized_train_data = dict()\n",
    "        for key, data in train_data.items():\n",
    "            stats[key] = get_data_stats(data)\n",
    "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
    "\n",
    "        self.indices = indices\n",
    "        self.stats = stats\n",
    "        self.normalized_train_data = normalized_train_data\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.action_horizon = action_horizon\n",
    "        self.obs_horizon = obs_horizon\n",
    "\n",
    "    def __len__(self):\n",
    "        # all possible segments of the dataset\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get the start/end indices for this datapoint\n",
    "        buffer_start_idx, buffer_end_idx, \\\n",
    "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
    "\n",
    "        # get nomralized data using these indices\n",
    "        nsample = sample_sequence(\n",
    "            train_data=self.normalized_train_data,\n",
    "            sequence_length=self.pred_horizon,\n",
    "            buffer_start_idx=buffer_start_idx,\n",
    "            buffer_end_idx=buffer_end_idx,\n",
    "            sample_start_idx=sample_start_idx,\n",
    "            sample_end_idx=sample_end_idx\n",
    "        )\n",
    "\n",
    "        # discard unused observations\n",
    "        nsample['obs'] = nsample['obs'][:self.obs_horizon,:]\n",
    "        return nsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2622/2622 [00:00<00:00, 7920.67it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/robodiff/lib/python3.9/site-packages/zarr/hierarchy.py:448\u001b[0m, in \u001b[0;36mGroup.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(item)\n\u001b[1;32m    449\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/robodiff/lib/python3.9/site-packages/zarr/hierarchy.py:429\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 429\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(item)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/felixw/diffusion_policy/state_dp.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrl/home/felixw/diffusion_policy/state_dp.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m meta\u001b[39m.\u001b[39mcreate_dataset(\u001b[39m'\u001b[39m\u001b[39mepisode_ends\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(episode_ends))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrl/home/felixw/diffusion_policy/state_dp.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# zarr.convenience.save_group('data/logged_plans_03.zarr', data_root)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsrl/home/felixw/diffusion_policy/state_dp.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m data_root\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/robodiff/lib/python3.9/site-packages/zarr/hierarchy.py:450\u001b[0m, in \u001b[0;36mGroup.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(item)\n\u001b[1;32m    449\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# read from folder \n",
    "data_folder  = os.path.join(os.path.abspath('../interactpolicy/ipolicy/'), 'data', 'logged_plans_03')\n",
    "data_files = sorted(os.listdir(data_folder))\n",
    "dataset_root = dict()\n",
    "episode_end = 0\n",
    "episode_ends = []\n",
    "action_list = []\n",
    "state_list = []\n",
    "\n",
    "for file in tqdm(data_files):\n",
    "    if '.txt' in file:\n",
    "        continue\n",
    "    plan = np.load(os.path.join(data_folder, file))\n",
    "    plan = np.concatenate([plan[0::10], plan[[-1]]], axis=0) # select every 10th step, making sure the last step is included\n",
    "    next_plan = np.concatenate([plan[1:], plan[[-1]]], axis=0)\n",
    "    \n",
    "    action = np.concatenate([next_plan[:, 10:13], next_plan[:, 8:10]], axis=1) # end effector position and gripper state\n",
    "    state = np.concatenate([plan[:, 10:13], plan[:, 8:10], plan[:, 13:16], plan[:, 20:23], plan[:, 27:30], plan[:, 34:37], \n",
    "                            plan[:, 41:44], plan[:, 48:51]], axis=1) # ee pos, gripper, red, green, blue, yellow, cyan, magenta\n",
    "    action_list.append(action)\n",
    "    state_list.append(state)\n",
    "    episode_end += len(plan)\n",
    "    episode_ends.append(episode_end) \n",
    "\n",
    "data_root = zarr.open_group('data/logged_plans_03.zarr', mode='w')\n",
    "data = data_root.create_group('data')\n",
    "data.create_dataset('action', data=np.concatenate(action_list, axis=0))\n",
    "data.create_dataset('state', data=np.concatenate(state_list, axis=0))\n",
    "meta = data_root.create_group('meta')\n",
    "meta.create_dataset('episode_ends', data=np.array(episode_ends))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tree' object has no attribute '_ipython_display_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniforge3/envs/robodiff/lib/python3.9/site-packages/IPython/core/formatters.py:922\u001b[0m, in \u001b[0;36mIPythonDisplayFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    920\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     method()\n\u001b[1;32m    923\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/robodiff/lib/python3.9/site-packages/zarr/util.py:538\u001b[0m, in \u001b[0;36mTreeViewer._ipython_display_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ipython_display_\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    537\u001b[0m     tree \u001b[39m=\u001b[39m tree_widget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroup, expand\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand, level\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevel)\n\u001b[0;32m--> 538\u001b[0m     tree\u001b[39m.\u001b[39;49m_ipython_display_()\n\u001b[1;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m tree\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tree' object has no attribute '_ipython_display_'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "/\n",
       " ├── data\n",
       " │   ├── action (395283, 5) float64\n",
       " │   └── state (395283, 23) float64\n",
       " └── meta\n",
       "     └── episode_ends (2621,) int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda_environment_macos.yaml  eval_real_robot.py          ray_train_multirun.py\n",
      "conda_environment_real.yaml   LICENSE                     README.md\n",
      "conda_environment.yaml        \u001b[0m\u001b[01;34mmedia\u001b[0m/                      setup.py\n",
      "demo_pusht.py                 Miniforge3-Linux-x86_64.sh  state_dp.ipynb\n",
      "demo_real_robot.py            multirun_metrics.py         \u001b[01;34mtests\u001b[0m/\n",
      "\u001b[01;34mdiffusion_policy\u001b[0m/             pyrightconfig.json          train.py\n",
      "eval.py                       ray_exec.py\n"
     ]
    }
   ],
   "source": [
    "mkdir get_data_stat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
